# ğŸ¤Ÿ LeituraMao - Reconhecedor de LIBRAS

Sistema de reconhecimento de **LIBRAS** (LÃ­ngua Brasileira de Sinais) em tempo real usando visÃ£o computacional e aprendizado de mÃ¡quina.

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [Funcionalidades](#-funcionalidades)
- [Requisitos do Sistema](#-requisitos-do-sistema)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Funciona](#-como-funciona)
- [CalibraÃ§Ã£o](#-calibraÃ§Ã£o)
- [Comandos Especiais](#-comandos-especiais)
- [ConfiguraÃ§Ãµes AvanÃ§adas](#-configuraÃ§Ãµes-avanÃ§adas)
- [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)

---

## ğŸ“– Sobre o Projeto

**LeituraMao** Ã© um projeto de acessibilidade que utiliza inteligÃªncia artificial para reconhecer gestos da **LÃ­ngua Brasileira de Sinais (LIBRAS)** atravÃ©s de uma webcam comum. O sistema captura os movimentos das mÃ£os em tempo real, identifica as letras do alfabeto LIBRAS e sintetiza as palavras em voz usando tecnologia Text-to-Speech.

### ğŸ¯ Objetivos

- Facilitar a comunicaÃ§Ã£o entre pessoas que usam LIBRAS e pessoas que nÃ£o conhecem a lÃ­ngua
- Fornecer uma ferramenta gratuita e acessÃ­vel para aprendizado de LIBRAS
- Demonstrar aplicaÃ§Ãµes prÃ¡ticas de visÃ£o computacional e IA

---

## âœ¨ Funcionalidades

### ğŸ”¤ Reconhecimento de Letras
- **26 letras do alfabeto LIBRAS** (A-Z)
- DetecÃ§Ã£o de **gestos com movimento** (J e Z)
- **Anti-fantasma**: Sistema de estabilidade que evita detecÃ§Ãµes falsas
- **CalibraÃ§Ã£o personalizada**: Ajuste o reconhecimento ao seu estilo de sinal

### ğŸ™ï¸ SÃ­ntese de Voz
- **ConversÃ£o texto-para-fala** usando Edge TTS
- **Voz em portuguÃªs brasileiro** (Microsoft Neural Voice)
- **Alta qualidade de Ã¡udio** sem limitaÃ§Ãµes de volume
- **ReproduÃ§Ã£o automÃ¡tica** quando vocÃª pressiona "ENTER"

### âŒ¨ï¸ Comandos Especiais
- **ENTER**: Fala a frase formada e limpa a tela
- **ESPAÃ‡O**: Adiciona espaÃ§o entre palavras
- **BACKSPACE**: Remove a Ãºltima letra (com delay anti-spam)

### ğŸ¥ Interface Visual
- **VisualizaÃ§Ã£o em tempo real** da mÃ£o detectada
- **Feedback visual** da letra identificada
- **Contador de estabilidade** para mostrar confianÃ§a da detecÃ§Ã£o
- **Overlay de informaÃ§Ãµes** mostrando o estado atual

---

## ğŸ’» Requisitos do Sistema

### Hardware
- **Webcam** (resoluÃ§Ã£o mÃ­nima 640x480)
- **Processador**: Intel i3 ou equivalente (recomendado i5+)
- **RAM**: 4GB mÃ­nimo (8GB recomendado)
- **Sistema Operacional**: Windows 10/11

### Software
- **Python 3.11+**
- **pip** (gerenciador de pacotes Python)

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/GianluccaPaiva/leituraMao.git
cd leituraMao
```

### 2. Crie o Ambiente Virtual

```bash
python -m venv venv
```

### 3. Ative o Ambiente Virtual

**Windows PowerShell:**
```powershell
Set-ExecutionPolicy -Scope Process Bypass
.\venv\Scripts\Activate.ps1
```

**Windows CMD:**
```cmd
venv\Scripts\activate.bat
```

### 4. Instale as DependÃªncias

```bash
pip install -r requirements.txt
```

### 5. Verifique a InstalaÃ§Ã£o

```bash
python main.py
```

Se tudo estiver correto, vocÃª verÃ¡ o menu principal.

---

## ğŸ“š Como Usar

### ğŸ¬ Iniciando o Sistema

1. **Execute o programa principal:**
   ```bash
   python main.py
   ```

2. **Escolha uma opÃ§Ã£o:**
   - `1` - Calibrar (primeira vez ou para adicionar/atualizar letras)
   - `2` - Iniciar reconhecimento

### ğŸ”§ Modo de CalibraÃ§Ã£o

Use este modo para **treinar** o sistema a reconhecer SEU estilo de sinal.

1. Digite `1` no menu principal
2. Posicione-se em frente Ã  webcam (iluminaÃ§Ã£o adequada)
3. Consulte uma **tabela de LIBRAS** para referÃªncia
4. FaÃ§a o sinal da letra desejada
5. Pressione a **tecla correspondente** (A-Z) no teclado
6. Uma mensagem confirmarÃ¡: `âœ… Letra X calibrada e salva!`
7. Pressione **ESC** para sair

**Dicas para boa calibraÃ§Ã£o:**
- IluminaÃ§Ã£o uniforme e clara
- Fundo neutro (sem muita movimentaÃ§Ã£o)
- MÃ£o bem visÃ­vel e estÃ¡vel
- DistÃ¢ncia de ~50cm da cÃ¢mera

### ğŸ¯ Modo de Reconhecimento

Use este modo para **converter LIBRAS em texto e voz**.

1. Digite `2` no menu principal
2. Posicione sua mÃ£o em frente Ã  cÃ¢mera
3. FaÃ§a os sinais das letras (mantenha por ~1 segundo)
4. A letra aparecerÃ¡ na tela quando **estabilizada**
5. Para **falar** a frase:
   - FaÃ§a o gesto configurado como "ENTER"
   - O sistema sintetizarÃ¡ voz e limparÃ¡ a frase
6. Pressione **Q** no teclado para sair

**Comandos durante o reconhecimento:**
- **ENTER**: Fala e limpa a frase
- **ESPAÃ‡O**: Adiciona espaÃ§o
- **BACKSPACE**: Remove Ãºltima letra (delay de 0.5s)

---

## ğŸ“‚ Estrutura do Projeto

```
leituraMao/
â”‚
â”œâ”€â”€ main.py                 # Ponto de entrada do programa
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”œâ”€â”€ README.md              # Este arquivo
â”œâ”€â”€ .gitignore             # Arquivos ignorados pelo Git
â”‚
â”œâ”€â”€ dados/
â”‚   â””â”€â”€ alfabeto.json      # Base de dados das letras calibradas
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py        # Marca o diretÃ³rio como pacote Python
    â”œâ”€â”€ calibrar.py        # MÃ³dulo de calibraÃ§Ã£o de letras
    â”œâ”€â”€ libra.py           # MÃ³dulo principal de reconhecimento
    â”œâ”€â”€ libras.py          # Classe para comparaÃ§Ã£o de padrÃµes
    â”œâ”€â”€ gestos.py          # ExtraÃ§Ã£o de features e detecÃ§Ã£o de movimento
    â”œâ”€â”€ mao.py             # DetecÃ§Ã£o de mÃ£o com MediaPipe
    â”œâ”€â”€ falador_frase.py   # SÃ­ntese de voz (TTS)
    â””â”€â”€ camera.py          # (Funcionalidade de cÃ¢mera - legado)
```

### ğŸ“„ DescriÃ§Ã£o dos MÃ³dulos

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `main.py` | Interface principal; menu de seleÃ§Ã£o entre calibrar e reconhecer |
| `calibrar.py` | Captura gestos e salva features no JSON |
| `libra.py` | Loop principal de reconhecimento em tempo real |
| `libras.py` | Algoritmo de comparaÃ§Ã£o (erro quadrÃ¡tico) |
| `gestos.py` | ExtraÃ§Ã£o de caracterÃ­sticas geomÃ©tricas da mÃ£o |
| `mao.py` | DetecÃ§Ã£o de landmarks da mÃ£o usando MediaPipe |
| `falador_frase.py` | SÃ­ntese de voz com Edge TTS e pygame |

---

## ğŸ”¬ Como Funciona

### 1ï¸âƒ£ DetecÃ§Ã£o da MÃ£o (MediaPipe)

O sistema usa **MediaPipe Hands** para detectar 21 pontos de referÃªncia (landmarks) na mÃ£o:

```
0: Pulso
1-4: Polegar (base â†’ ponta)
5-8: Indicador
9-12: MÃ©dio
13-16: Anelar
17-20: Mindinho
```

### 2ï¸âƒ£ ExtraÃ§Ã£o de Features

Para cada pose, calculamos **9 distÃ¢ncias normalizadas**:

- DistÃ¢ncia entre dedos consecutivos (thumb-index, index-middle, etc.)
- DistÃ¢ncia de cada dedo atÃ© o pulso
- NormalizaÃ§Ã£o pelo tamanho da mÃ£o (pulso â†’ dedo mÃ©dio)

### 3ï¸âƒ£ ComparaÃ§Ã£o de PadrÃµes

Usamos **erro quadrÃ¡tico** para comparar a pose atual com as poses calibradas:

```python
erro = Î£ (feature_atual - feature_calibrada)Â²
```

A letra com **menor erro** e **abaixo do limiar** Ã© reconhecida.

### 4ï¸âƒ£ Sistema Anti-Fantasma

Para evitar detecÃ§Ãµes falsas:

- **Contador de estabilidade**: Precisa manter a pose por 12+ frames
- **Limiar de erro estrito**: 0.18 (configÃºravel)
- **Intervalo entre letras**: 1.0 segundo
- **Delay de comandos especiais**: Backspace com 0.5s

### 5ï¸âƒ£ DetecÃ§Ã£o de Movimento (J e Z)

Letras **J** e **Z** requerem movimento:

- **J**: Detecta movimento descendente com curva lateral (mindinho)
- **Z**: Detecta movimento em zig-zag (indicador)
- Rastreamento de 15 posiÃ§Ãµes histÃ³ricas

---

## ğŸ¨ CalibraÃ§Ã£o

### Por que calibrar?

Cada pessoa faz sinais de forma ligeiramente diferente. A calibraÃ§Ã£o personaliza o sistema para **seu estilo**.

### Como calibrar uma letra

1. Inicie o modo de calibraÃ§Ã£o (`1` no menu)
2. FaÃ§a o sinal da letra (ex: "A")
3. Pressione a tecla `A` no teclado
4. O sistema salva as **features geomÃ©tricas** em `dados/alfabeto.json`

### Recalibrando letras problemÃ¡ticas

Se uma letra nÃ£o estÃ¡ sendo reconhecida corretamente:

1. Entre no modo de calibraÃ§Ã£o
2. RefaÃ§a o sinal com atenÃ§Ã£o Ã :
   - IluminaÃ§Ã£o adequada
   - MÃ£o totalmente visÃ­vel
   - Pose estÃ¡vel por 1-2 segundos
3. Pressione a tecla para sobrescrever a calibraÃ§Ã£o anterior

---

## âš™ï¸ Comandos Especiais

### ENTER

**FunÃ§Ã£o**: Fala a frase acumulada e limpa o buffer

**Como configurar**:
1. Decida qual gesto serÃ¡ "ENTER" (ex: mÃ£o fechada com polegar levantado)
2. Calibre esse gesto com o nome "ENTER"
3. No reconhecimento, faÃ§a o gesto e aguarde ~1 segundo

### ESPAÃ‡O

**FunÃ§Ã£o**: Adiciona um espaÃ§o entre palavras

**ConfiguraÃ§Ã£o**: Calibre um gesto como "ESPACO"

### BACKSPACE

**FunÃ§Ã£o**: Remove a Ãºltima letra (com delay de 0.5s)

**ConfiguraÃ§Ã£o**: Calibre um gesto como "\b" (caractere de backspace)

**CaracterÃ­sticas**:
- Delay de 0.5s entre execuÃ§Ãµes
- Pode ser usado mÃºltiplas vezes (saia e volte Ã  pose)
- NÃ£o spama se vocÃª mantiver a pose

---

## ğŸ› ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Ajustar Sensibilidade

Edite `src/libra.py`:

```python
LIMITE_ESTABILIDADE = 12    # Frames para confirmar (â†‘ = mais estÃ¡vel)
LIMIAR_ERRO_ESTRITO = 0.18  # PrecisÃ£o (â†“ = mais rigoroso)
TEMPO_ENTRE_LETRAS = 1.0    # Delay entre letras (segundos)
DELAY_BACKSPACE = 0.5       # Delay do backspace (segundos)
```

### Trocar Voz do TTS

Edite `src/falador_frase.py`:

```python
self.voice = "pt-BR-AntonioNeural"  # Voz masculina
# Outras opÃ§Ãµes:
# "pt-BR-FranciscaNeural" - Voz feminina
# "pt-BR-BrendaNeural"    - Voz feminina alternativa
```

### Ajustar Velocidade da Fala

```python
self.rate = "+0%"   # Velocidade neutra
# Exemplos:
# "+20%" - Mais rÃ¡pido
# "-20%" - Mais lento
```

### Mudar ResoluÃ§Ã£o da CÃ¢mera

Edite `src/libra.py`:

```python
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
```

---

## ğŸ› SoluÃ§Ã£o de Problemas

### âŒ Erro: "No module named 'cv2'"

**SoluÃ§Ã£o**: Reinstale o OpenCV
```bash
pip uninstall opencv-python opencv-contrib-python
pip install opencv-python
```

### âŒ CÃ¢mera nÃ£o abre

**PossÃ­veis causas**:
- Outra aplicaÃ§Ã£o estÃ¡ usando a cÃ¢mera
- PermissÃµes negadas no Windows

**SoluÃ§Ã£o**:
1. Feche outros programas que usam cÃ¢mera (Zoom, Teams, etc.)
2. Verifique permissÃµes: ConfiguraÃ§Ãµes â†’ Privacidade â†’ CÃ¢mera

### âŒ Letras nÃ£o sÃ£o reconhecidas

**SoluÃ§Ãµes**:
1. **Recalibre** a letra problemÃ¡tica
2. Melhore a **iluminaÃ§Ã£o** do ambiente
3. Use **fundo neutro** (parede clara)
4. Verifique se a mÃ£o estÃ¡ **totalmente visÃ­vel**
5. Diminua `LIMIAR_ERRO_ESTRITO` (mais permissivo)

### âŒ Reconhecimento instÃ¡vel ("fantasmas")

**SoluÃ§Ãµes**:
1. Aumente `LIMITE_ESTABILIDADE` (mais frames)
2. Diminua `LIMIAR_ERRO_ESTRITO` (mais rigoroso)
3. Mantenha a pose mais tempo
4. Evite movimentos bruscos

### âŒ Voz nÃ£o funciona

**SoluÃ§Ã£o**:
1. Verifique se pygame estÃ¡ instalado: `pip install pygame`
2. Teste volume do sistema
3. Verifique se Edge TTS estÃ¡ funcionando:
   ```bash
   edge-tts --text "teste" --write-media teste.mp3
   ```

### âŒ Import "src.falador_frase" could not be resolved (Pylance)

**SoluÃ§Ã£o**: Este Ã© apenas um aviso do Pylance. O cÃ³digo funciona normalmente. Para corrigir:
1. Pressione `Ctrl+Shift+P`
2. Digite "Python: Restart Language Server"

---

## ğŸ”§ Tecnologias Utilizadas

### VisÃ£o Computacional
- **OpenCV** - Captura e processamento de vÃ­deo
- **MediaPipe** - DetecÃ§Ã£o de landmarks da mÃ£o

### InteligÃªncia Artificial
- **Algoritmo de KNN personalizado** - Reconhecimento de padrÃµes
- **Erro quadrÃ¡tico** - MÃ©trica de similaridade

### SÃ­ntese de Voz
- **Edge TTS** - Text-to-Speech da Microsoft
- **Pygame** - ReproduÃ§Ã£o de Ã¡udio MP3

### Desenvolvimento
- **Python 3.11** - Linguagem principal
- **NumPy** - OperaÃ§Ãµes matemÃ¡ticas
- **Asyncio** - ProgramaÃ§Ã£o assÃ­ncrona

---

## ğŸ“Š EstatÃ­sticas de Performance

| MÃ©trica | Valor |
|---------|-------|
| Taxa de quadros | ~30 FPS |
| LatÃªncia de detecÃ§Ã£o | ~40ms |
| Accuracy (apÃ³s calibraÃ§Ã£o) | ~85-95% |
| Tempo de sÃ­ntese TTS | ~1-2s |

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um **fork** do projeto
2. Crie uma **branch** para sua feature (`git checkout -b feature/MinhaFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. **Push** para a branch (`git push origin feature/MinhaFeature`)
5. Abra um **Pull Request**

### Ideias de ContribuiÃ§Ã£o

- [ ] Suporte para outras plataformas (Linux, macOS)
- [ ] Reconhecimento de palavras inteiras (nÃ£o sÃ³ alfabeto)
- [ ] Interface grÃ¡fica (GUI) com Tkinter ou PyQt
- [ ] Modo de treinamento com mais exemplos por letra
- [ ] Suporte para mÃºltiplas lÃ­nguas de sinais
- [ ] ExportaÃ§Ã£o de frases para arquivo de texto

---

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## ğŸ‘¨â€ğŸ’» Autor

**Gianlucca Paiva**

- GitHub: [@GianluccaPaiva](https://github.com/GianluccaPaiva)
- RepositÃ³rio: [leituraMao](https://github.com/GianluccaPaiva/leituraMao)

---

## ğŸ™ Agradecimentos

- **MediaPipe** - Por fornecer uma soluÃ§Ã£o robusta de detecÃ§Ã£o de mÃ£os
- **Comunidade LIBRAS** - Por tornar possÃ­vel a comunicaÃ§Ã£o inclusiva
- **Microsoft** - Pelo Edge TTS de alta qualidade

---

## ğŸ“ Suporte

Se vocÃª encontrar problemas ou tiver dÃºvidas:

1. Verifique a seÃ§Ã£o [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)
2. Abra uma **Issue** no GitHub
3. Consulte a documentaÃ§Ã£o das bibliotecas utilizadas

---

## ğŸ“ ReferÃªncias

- [DocumentaÃ§Ã£o MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- [OpenCV Documentation](https://docs.opencv.org/)
- [Edge TTS GitHub](https://github.com/rany2/edge-tts)
- [Alfabeto LIBRAS](http://www.acessibilidadebrasil.org.br/libras/)

---

**Feito com â¤ï¸ para promover acessibilidade e inclusÃ£o.**

ğŸ¤Ÿ **LIBRAS Ã© linguagem, nÃ£o sÃ³ gestos!** ğŸ¤Ÿ
